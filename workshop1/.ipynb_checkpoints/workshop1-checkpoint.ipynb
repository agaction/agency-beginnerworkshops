{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop 1: Using Numpy to Implement Forward Pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy Arrays\n",
    "\n",
    "In order to implement a Neural Network, we will need a convenient way to perform matrix operations. \n",
    "\n",
    "Thankfully, Numpy provides a simple way to create and work with matrices, in the form ndarrays (n-dimensional arrays). We can use ndarrays to represent vectors, matrices, or even tensors (higher dimensional matrices). Before we get into creating a Neural Network, let's briefly learn the basics of ndarrays. We'll start by creating a simple array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([1, 2, 3, 4])\n",
    "\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, we can think of ndarrays similarly to the way we think of matrices or vectors. What do you think are the dimensions of A? Is it 4 x 1? Something else? Discuss among your group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of A: (4,)\n"
     ]
    }
   ],
   "source": [
    "# We can find the dimensions of A like so:\n",
    "dim_A = A.shape\n",
    "\n",
    "print(\"Dimensions of A: \" + str(dim_A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it turns out, A is neither 1 x 4 or 4 x 1. Instead, it is a one-dimensional array, or flattened array, of dimenson 4. Whenever we want to represent vectors in Numpy, we will use one-dimensional arrays. For operations like matrix multiplication, a one-dimensional array can fulfill the role of either a 4 x 1 or 1 x 4 matrix, so they are quite versatile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can index into one-dimensional arrays to grab individual indices or slices. You can also modify entries of arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[2 3]\n",
      "Before modifying: [1 2 3 4]\n",
      "After modifying: [1 2 7 4]\n"
     ]
    }
   ],
   "source": [
    "x = A[0]\n",
    "print(x)\n",
    "\n",
    "a_slice = A[1:3]\n",
    "print(a_slice)\n",
    "\n",
    "print(\"Before modifying: {}\".format(A))\n",
    "A[2] = 7\n",
    "print(\"After modifying: {}\".format(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make another array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]\n",
      " [13 14 15 16]]\n"
     ]
    }
   ],
   "source": [
    "B = np.array([ [1, 2, 3, 4],\n",
    "               [5, 6, 7, 8],\n",
    "               [9, 10, 11, 12],\n",
    "               [13, 14, 15, 16] ])\n",
    "\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the dimensions of B? Find the dimensions and print them below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: print the dimensions of B below\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B is a two-dimensional array. These are useful for representing matrices, and they behave similarly to matrices in consideration to most operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also index into two-dimensional arrays. However, we have more options, as there are two dimensions of indices to index into as opposed to one. Look at some of the following examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A single entry: 3\n",
      "The first column: [ 1  5  9 13]\n",
      "The first row: [1 2 3 4]\n",
      "The second row: [5 6 7 8]\n",
      "A crop from B:\n",
      "[[2 3]\n",
      " [6 7]]\n"
     ]
    }
   ],
   "source": [
    "y = B[0, 2]\n",
    "print(\"A single entry: {}\".format(y))\n",
    "\n",
    "column1 = B[:, 0]\n",
    "print(\"The first column: {}\".format(column1))\n",
    "\n",
    "row1 = B[0, :]\n",
    "row2 = B[1]    # we can opt to leave out the second index, numpy will fetch everything in the 2nd dimension\n",
    "print(\"The first row: {}\".format(row1))\n",
    "print(\"The second row: {}\".format(row2))\n",
    "\n",
    "crop = B[0:2, 1:3]\n",
    "print(\"A crop from B:\\n{}\".format(crop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: print one slice containing the last three entries of the third column of B\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that indexing individual entries will yield scalars; indexing rows or columns will yield one-dimensional arrays; and indexing crops or submatrices will yield a two-dimensional array.\n",
    "\n",
    "We see that scalar entries make up one-dimensional arrays, which can then be used to make up two-dimensional arrays. It is also true that two-dimensional arrays can be used to make up three-dimensional arrays. In general, n-dimensional arrays can be thought of as a collection of (n - 1)-dimensional arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can represent matrix multiplication and matrix-vector multiplication with np.dot()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[126 140 154 168]\n",
      "\n",
      "[ 42  98 154 210]\n"
     ]
    }
   ],
   "source": [
    "right_product = np.dot(A, B)\n",
    "print(right_product)\n",
    "print()\n",
    "\n",
    "left_product = np.dot(B, A)\n",
    "print(left_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to matrix multiplication, the order in which you enter arguments into np.dot() is very important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Print out the product between the upper-leftmost 3 x 3 crop of B and the lower-rightmost 3 x 3 crop of B\n",
    "###       Then, replace the upper-rightmost 3 x 3 section of B with that product, and print B\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to instantiate ndarrays in numpy. Here are two common ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [0. 0.]]\n",
      "\n",
      "[[0.00210941 0.03980142 0.25715043]\n",
      " [0.22498141 0.22288702 0.80170878]\n",
      " [0.28910275 0.5658836  0.64027261]\n",
      " [0.46922218 0.14394224 0.80510457]]\n"
     ]
    }
   ],
   "source": [
    "zero_array = np.zeros((2, 2))\n",
    "print(zero_array)\n",
    "print()\n",
    "\n",
    "random_array = np.random.rand(4, 3)  # fills array with values between 0 and 1\n",
    "print(random_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of these ways of instantiating arrays involve entering the desired dimensions into their respective functions. However, np.zeros() requires the dimensions to be contained inside parentheses, while np.random.rand() wants the dimensions to be entered as separate arguments. These small details are always difficult to remember, so you may often have to refer to the [numpy documentation](https://docs.scipy.org/doc/numpy/reference/index.html \"Numpy Documentation\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Constuct a random 5 x 4 array. Matrix multiply this with B and then print the result.\n",
    "###       Remember, order matters!\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Pass\n",
    "\n",
    "Now that we know some basics of Numpy, we can begin to implement our Neural Network that will solve the MNIST problem. For today, we will only implement the forward pass.\n",
    "\n",
    "However, before we can start writing the network, we will need the image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data():\n",
    "    f = open('mnist_train.csv', 'r')\n",
    "    \n",
    "    lines = f.readlines()\n",
    "    \n",
    "    training_images = np.zeros((len(lines), 784))\n",
    "    training_labels = np.zeros((len(lines), 10))\n",
    "    index = 0\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        stringlist = line.split(\",\")\n",
    "        \n",
    "        # fill the image array\n",
    "        for h in range(784):\n",
    "            training_images[index, h] = float(stringlist[h + 1])\n",
    "        \n",
    "        #fill the label array\n",
    "        answer = int(stringlist[0])\n",
    "        training_labels[index, answer - 1] = 1.0\n",
    "        index += 1\n",
    "        \n",
    "\n",
    "    f.close()\n",
    "    \n",
    "    return training_images / 255, training_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wrote a function that grabs the image data from the included csv file and puts it into an ndarray. When you move on to doing your own problems, you will have to learn solve tasks like these. But for now we will just use the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images, training_labels = get_training_data()\n",
    "\n",
    "### TODO: Print the shapes of training_images and training_data. What do these dimensions mean? Can you explain why\n",
    "###       they are of that size?\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data, we can create our Neural Network. We will take an object-oriented approach by creating a NeuralNetwork class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    \"\"\"\n",
    "    A Fully Connected Neural Network. There are 784 input layer nodes, 12 hidden layer nodes, and 10 output layer\n",
    "    nodes.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \n",
    "        \n",
    "        # First, we instantiate an array to hold all the weights from the input layer to the hidden layer.\n",
    "        # Look at the line of code and discuss with your group what you think each part of it is doing.\n",
    "        # Hint: You may need to google numpy.full\n",
    "        self.W1 = np.full((784, 12), -1) + 2 * np.random.rand(784, 12)\n",
    "        \n",
    "        \n",
    "        ### TODO: Initialize random values for W2, the weights from the hidden layer to the\n",
    "        ###       output layer.\n",
    "        self.W2 = np.full((12, 10), -1) + 2 * np.random.rand(12, 10)\n",
    "        ###\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Now, we instantiate an array to hold the biases for the hidden layer nodes\n",
    "        self.B1 = np.full((12, ), -1) + 2 * np.random.rand(12)\n",
    "        \n",
    "        \n",
    "        ### TODO: Initialize random values for B2, the biases for output layer nodes\n",
    "        self.B2 = np.full((10, ), -1) + 2 * np.random.rand(10)\n",
    "        ###\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Given an individual input vector, forward propogate through the network.\n",
    "        \n",
    "        Parameters:\n",
    "        x: input vector representing image data, one-dimensional vector\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        # Remember, the input vector is going to be an unrolled image -- a vector of 784 pixels\n",
    "        # We can represent the multiplication of all inputs by their respective weights to nodes in one matrix\n",
    "        # multiplication. We then add the biases to this result through an entrywise addition.\n",
    "        # Then, we apply our activation function. For now, we will use the hyperbolic tangent function.\n",
    "        # O1 is the vector of values that end up in the hidden layer nodes.\n",
    "        Z1 = np.dot(x, self.W1) + self.B1\n",
    "        O1 = np.tanh(Z1)\n",
    "        \n",
    "        \n",
    "        ### TODO: Calculate O2, the vector of values that ends up in the output layer nodes.\n",
    "        Z2 = np.dot(O1, self.W2) + self.B2\n",
    "        O2 = np.tanh(Z2)\n",
    "        ###\n",
    "        \n",
    "        return O2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets instantiate a Neural Network object now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can call methods using the \".\" operator, just like in Java. Index into training_images to get the first image, then input that image vector into net.forward(). Print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.62622671e-01, -9.93998181e-01,  6.72716610e-01,  9.57574730e-01,\n",
       "        9.74334217e-01,  9.33191307e-01,  6.06499679e-01, -1.67075137e-04,\n",
       "        9.94912674e-01,  9.27236001e-01])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TODO: Index into training_images to get the first image, then input that image vector into net.forward().\n",
    "###       Print the result.\n",
    "net.forward(training_images[0])\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you have successfully implemented the forward pass. Right now, the output is meaningless; however, in the future we will be able to use this to perform gradient descent. See you next week!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
